{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr8PUbElrhWK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
        "device"
      ],
      "metadata": {
        "id": "9g9P1qEtwtFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transform.Compose([transform.Resize((32,32)),\n",
        "                               transform.ToTensor(),\n",
        "                               transform.Normalize((0.5,),(0.5,))])  \n",
        "\n",
        "trainset = datasets.CIFAR10('./data', download                               =True, train=True, transform=transform)\n",
        "testset = datasets.CIFAR10('./', download=True, train=False, transform=transform)\n"
      ],
      "metadata": {
        "id": "SLyExtXBsnxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainData = torch.utils.data.DataLoader(trainset,batch_size=2000,shuffle=True)\n",
        "TestData = torch.utils.data.DataLoader(testset,batch_size=2000, shuffle=False)\n",
        "TestData"
      ],
      "metadata": {
        "id": "eFqbr65Ms2vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of training data\n",
        "dataiter = iter(TrainData)\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape,labels)\n",
        "np.unique(labels)"
      ],
      "metadata": {
        "id": "nsnK_DR2tJi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataiter = iter(TestData)\n",
        "# images, labels = dataiter.next()\n",
        "# print(images.shape,labels)"
      ],
      "metadata": {
        "id": "51VhpzqntO-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classname=['plane','car','bird','cat','dear','dog','frog','horse','ship','truck']  "
      ],
      "metadata": {
        "id": "UmYun8-juUDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "for i in range(10):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(images[i].permute(1, 2, 0))\n",
        "  plt.xlabel(classname[labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eLwsNUfrulV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN_Digit_model(nn.Module):  \n",
        "        def __init__(self):  \n",
        "            super().__init__()  \n",
        "             \n",
        "            self.conv1=nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5)  \n",
        "            self.conv2=nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)  \n",
        "            self.fully1=nn.Linear(in_features=64*5*5,out_features=128)  \n",
        "            self.fully2=nn.Linear(in_features=128,out_features=210) \n",
        "            self.out=nn.Linear(in_features=210,out_features=10)  \n",
        "        def forward(self,x):  \n",
        "            x=F.relu(self.conv1(x))  \n",
        "            x=F.max_pool2d(x,kernel_size=2,stride=2)  \n",
        "            x=F.relu(self.conv2(x))  \n",
        "            x=F.max_pool2d(x,kernel_size=2,stride=2)  \n",
        "            x=x.view(x.size(0),-1) #we can also use like this  x.view(12*4*4,-1) \n",
        "            x=F.relu(self.fully1(x)) \n",
        "            x= F.relu(self.fully2(x))\n",
        "            x=self.out(x)\n",
        "            return x this may represent a good starting point on your problem."
      ],
      "metadata": {
        "id": "hayA7VUWwOZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model ,optimizer,loss_function\n",
        "model = CNN_Digit_model().to(device)  \n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001\n",
        "                             )\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "TyM-opmxwb8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=15\n",
        "for e in range(epochs):  \n",
        "    for train_img,train_labels in TrainData:  \n",
        "        train_img=train_img.to(device)\n",
        "        train_labels=train_labels.to(device)\n",
        "\n",
        "        outputs=model(train_img) \n",
        "        loss1=loss_function(outputs,train_labels)  \n",
        "        \n",
        "        optimizer.zero_grad()  \n",
        "        loss1.backward()   \n",
        "        \n",
        "\n",
        "        optimizer.step()  \n",
        "\n",
        "      \n",
        "      \n",
        "        \n",
        "        \n",
        "        print(\"Epoch {}/{}, Loss: {:.3f}\".format(e+1,epochs, loss1.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "f75BDT_Dwd9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im_convert(tensor):  \n",
        "    image=tensor.cpu().clone().detach().numpy()  \n",
        "    image=image.transpose(1,2,0)  \n",
        "    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n",
        "    image=image.clip(0,1)\n",
        "    return image "
      ],
      "metadata": {
        "id": "CE7x7ik6whjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import image\n",
        "accuracy=0\n",
        "total=0\n",
        "for images,labels in TestData:  \n",
        "    images_in=images.to(device) \n",
        "    print(len(images)) \n",
        "    labels=labels.to(device)\n",
        "    output=model(images_in) \n",
        "    _,preds=torch.max(output,1)\n",
        "    val_loss1=loss_function(output,labels)\n",
        "       \n",
        "    total += images.size(0)\n",
        "    accuracy += (preds == labels).sum().item()  \n",
        "\n",
        "acc = 100.0 * accuracy / total\n",
        "print(f'Accuracy of the network on the 10000 test images: {acc} %') \n"
      ],
      "metadata": {
        "id": "QlHNaigdwjx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(180,200))\n",
        "for i in range(100):  \n",
        "  \n",
        "  ax=fig.add_subplot(10,10,i+1)\n",
        "  \n",
        "  plt.imshow(images[i].permute(1, 2, 0))  \n",
        "  ax.set_title(\"{}, ({})\".format(str(classname[preds[i].item()]),str(classname[labels[i].item()])),  \n",
        "  color=(\"red\" if preds[i]==labels[i] else \"blue\"),fontsize = 90)  \n",
        "plt.show"
      ],
      "metadata": {
        "id": "78KDFJvbwmLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}